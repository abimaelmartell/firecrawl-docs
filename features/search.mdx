---
title: "Search"
description: "Search the web and get full content from results"
og:title: "Search | Firecrawl"
og:description: "Search the web and get full page content from results"
icon: "magnifying-glass"
---

import InstallationPython from "/snippets/v1/installation/python.mdx";
import InstallationNode from "/snippets/v1/installation/js.mdx";
import InstallationGo from "/snippets/v1/installation/go.mdx";
import InstallationRust from "/snippets/v1/installation/rust.mdx";
import SearchPython from "/snippets/v1/search/base/python.mdx";
import SearchNode from "/snippets/v1/search/base/js.mdx";
import SearchCURL from "/snippets/v1/search/base/curl.mdx";
import SearchContentPython from "/snippets/v1/search/content/python.mdx";
import SearchContentNode from "/snippets/v1/search/content/js.mdx";
import SearchContentCURL from "/snippets/v1/search/content/curl.mdx";
import SearchLocationPython from "/snippets/v1/search/location/python.mdx";
import SearchLocationNode from "/snippets/v1/search/location/js.mdx";
import SearchLocationCURL from "/snippets/v1/search/location/curl.mdx";
import SearchTimePython from "/snippets/v1/search/time/python.mdx";
import SearchTimeNode from "/snippets/v1/search/time/js.mdx";
import SearchTimeCURL from "/snippets/v1/search/time/curl.mdx";

Firecrawl's search API allows you to perform web searches and optionally scrape the search results in one operation.

- Choose specific output formats (markdown, HTML, links, screenshots)
- Search the web with customizable parameters (location, etc.)
- Optionally retrieve content from search results in various formats
- Control the number of results and set timeouts

For details, see the [Search Endpoint API Reference](https://docs.firecrawl.dev/api-reference/endpoint/search).

## Performing a Search with Firecrawl

### /search endpoint

Used to perform web searches and optionally retrieve content from the results.

### Installation 

<CodeGroup>

  <InstallationPython />

  <InstallationNode />

  <InstallationGo />
  
  <InstallationRust />

</CodeGroup>

### Basic Usage

<CodeGroup>

  <SearchPython />

  <SearchNode />
  
  <SearchCURL />

</CodeGroup>

### Response

SDKs will return the data object directly. cURL will return the complete payload.

```json
{
  "success": true,
  "data": [
    {
      "title": "Firecrawl - The Ultimate Web Scraping API",
      "description": "Firecrawl is a powerful web scraping API that turns any website into clean, structured data for AI and analysis.",
      "url": "https://firecrawl.dev/"
    },
    {
      "title": "Web Scraping with Firecrawl - A Complete Guide",
      "description": "Learn how to use Firecrawl to extract data from websites effortlessly.",
      "url": "https://firecrawl.dev/guides/web-scraping/"
    },
    {
      "title": "Firecrawl Documentation - Getting Started",
      "description": "Official documentation for the Firecrawl web scraping API.",
      "url": "https://docs.firecrawl.dev/"
    }
    // ... more results
  ]
}
```

## Search with Content Scraping

Search and retrieve content from the search results in one operation.

<CodeGroup>

  <SearchContentPython />

  <SearchContentNode />
  
  <SearchContentCURL />

</CodeGroup>

### Response with Scraped Content

```json
{
  "success": true,
  "data": [
    {
      "title": "Firecrawl - The Ultimate Web Scraping API",
      "description": "Firecrawl is a powerful web scraping API that turns any website into clean, structured data for AI and analysis.",
      "url": "https://firecrawl.dev/",
      "markdown": "# Firecrawl\n\nThe Ultimate Web Scraping API\n\n## Turn any website into clean, structured data\n\nFirecrawl makes it easy to extract data from websites for AI applications, market research, content aggregation, and more...",
      "links": [
        "https://firecrawl.dev/pricing",
        "https://firecrawl.dev/docs",
        "https://firecrawl.dev/guides",
        // ... more links
      ],
      "metadata": {
        "title": "Firecrawl - The Ultimate Web Scraping API",
        "description": "Firecrawl is a powerful web scraping API that turns any website into clean, structured data for AI and analysis.",
        "sourceURL": "https://firecrawl.dev/",
        "statusCode": 200
      }
    },
    // ... more results
  ]
}
```

## Advanced Search Options

Firecrawl's search API supports various parameters to customize your search:

### Location Customization

<CodeGroup>

  <SearchLocationPython />

  <SearchLocationNode />
  
  <SearchLocationCURL />

</CodeGroup>

### Time-Based Search

Use the `tbs` parameter to filter results by time:

<CodeGroup>

  <SearchTimePython />

  <SearchTimeNode />
  
  <SearchTimeCURL />

</CodeGroup>

Common `tbs` values:
- `qdr:h` - Past hour
- `qdr:d` - Past 24 hours
- `qdr:w` - Past week
- `qdr:m` - Past month
- `qdr:y` - Past year

### Custom Timeout

Set a custom timeout for search operations:

<CodeGroup>

```python Python
from firecrawl import FirecrawlApp

# Initialize the client with your API key
app = FirecrawlApp(api_key="fc-YOUR_API_KEY")

# Set a 30-second timeout
search_result = app.search(
    "complex search query",
    limit=10,
    timeout=30000  # 30 seconds in milliseconds
)
```

```js JavaScript
import FirecrawlApp from '@mendable/firecrawl-js';

// Initialize the client with your API key
const app = new FirecrawlApp({apiKey: "fc-YOUR_API_KEY"});

// Set a 30-second timeout
app.search("complex search query", {
  limit: 10,
  timeout: 30000  // 30 seconds in milliseconds
})
.then(searchResult => {
  // Process results
  console.log(searchResult.data);
});
```

```bash cURL
curl -X POST https://api.firecrawl.dev/v1/search \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer fc-YOUR_API_KEY" \
  -d '{
    "query": "complex search query",
    "limit": 10,
    "timeout": 30000
  }'
```

</CodeGroup>

## Scraping Options

When scraping search results, you can specify multiple output formats and advanced scraping options:

<CodeGroup>

```python Python
from firecrawl import FirecrawlApp, ScrapeOptions

# Initialize the client with your API key
app = FirecrawlApp(api_key="fc-YOUR_API_KEY")

# Get search results with multiple formats
search_result = app.search(
    "firecrawl features",
    limit=3,
    scrape_options=ScrapeOptions(formats=["markdown", "html", "links", "screenshot"])
)
```

```js JavaScript
import FirecrawlApp from '@mendable/firecrawl-js';

// Initialize the client with your API key
const app = new FirecrawlApp({apiKey: "fc-YOUR_API_KEY"});

// Get search results with multiple formats
app.search("firecrawl features", {
  limit: 3,
  scrapeOptions: {
    formats: ["markdown", "html", "links", "screenshot"]
  }
})
.then(searchResult => {
  // Process results with various formats
  console.log(searchResult.data);
});
```

```bash cURL
curl -X POST https://api.firecrawl.dev/v1/search \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer fc-YOUR_API_KEY" \
  -d '{
    "query": "firecrawl features",
    "limit": 3,
    "scrapeOptions": {
      "formats": ["markdown", "html", "links", "screenshot"]
    }
  }'
```

</CodeGroup>

Available formats:
- `markdown`: Clean, formatted markdown content
- `html`: Processed HTML content
- `rawHtml`: Unmodified HTML content
- `links`: List of links found on the page
- `screenshot`: Screenshot of the page
- `screenshot@fullPage`: Full-page screenshot
- `extract`: Structured data extraction

## Advanced Scraping Options

The search endpoint supports all the same scraping options as the `/scrape` endpoint. Here are the key options you can use:

### Content Filtering

Control what content gets extracted from search results:

<CodeGroup>

```python Python
from firecrawl import FirecrawlApp, ScrapeOptions

app = FirecrawlApp(api_key="fc-YOUR_API_KEY")

search_result = app.search(
    "python tutorials",
    limit=5,
    scrape_options=ScrapeOptions(
        formats=["markdown"],
        includeTags=["article", "main", "div.content"],
        excludeTags=["nav", "footer", "aside"],
        onlyMainContent=True
    )
)
```

```js JavaScript
import FirecrawlApp from '@mendable/firecrawl-js';

const app = new FirecrawlApp({apiKey: "fc-YOUR_API_KEY"});

app.search("python tutorials", {
  limit: 5,
  scrapeOptions: {
    formats: ["markdown"],
    includeTags: ["article", "main", "div.content"],
    excludeTags: ["nav", "footer", "aside"],
    onlyMainContent: true
  }
});
```

```bash cURL
curl -X POST https://api.firecrawl.dev/v1/search \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer fc-YOUR_API_KEY" \
  -d '{
    "query": "python tutorials",
    "limit": 5,
    "scrapeOptions": {
      "formats": ["markdown"],
      "includeTags": ["article", "main", "div.content"],
      "excludeTags": ["nav", "footer", "aside"],
      "onlyMainContent": true
    }
  }'
```

</CodeGroup>

### PDF Parsing

**Important**: PDF parsing affects the cost of your search request. Each PDF page counts as 1 credit instead of 1 credit per URL.

<CodeGroup>

```python Python
from firecrawl import FirecrawlApp, ScrapeOptions

app = FirecrawlApp(api_key="fc-YOUR_API_KEY")

# Enable PDF parsing (default: true)
search_result = app.search(
    "research papers filetype:pdf",
    limit=3,
    scrape_options=ScrapeOptions(
        formats=["markdown"],
        parsePDF=True
    )
)

# Disable PDF parsing to avoid extra costs
search_result = app.search(
    "research papers",
    limit=5,
    scrape_options=ScrapeOptions(
        formats=["markdown"],
        parsePDF=False
    )
)
```

```js JavaScript
import FirecrawlApp from '@mendable/firecrawl-js';

const app = new FirecrawlApp({apiKey: "fc-YOUR_API_KEY"});

// Enable PDF parsing (default: true)
app.search("research papers filetype:pdf", {
  limit: 3,
  scrapeOptions: {
    formats: ["markdown"],
    parsePDF: true
  }
});

// Disable PDF parsing to avoid extra costs
app.search("research papers", {
  limit: 5,
  scrapeOptions: {
    formats: ["markdown"],
    parsePDF: false
  }
});
```

```bash cURL
# Enable PDF parsing (default: true)
curl -X POST https://api.firecrawl.dev/v1/search \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer fc-YOUR_API_KEY" \
  -d '{
    "query": "research papers filetype:pdf",
    "limit": 3,
    "scrapeOptions": {
      "formats": ["markdown"],
      "parsePDF": true
    }
  }'

# Disable PDF parsing to avoid extra costs
curl -X POST https://api.firecrawl.dev/v1/search \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer fc-YOUR_API_KEY" \
  -d '{
    "query": "research papers",
    "limit": 5,
    "scrapeOptions": {
      "formats": ["markdown"],
      "parsePDF": false
    }
  }'
```

</CodeGroup>

### Stealth Mode and Proxy Options

For websites with advanced anti-bot protection, use stealth mode. **Note**: Stealth mode costs +4 additional credits per search result (5 total credits per result).

<CodeGroup>

```python Python
from firecrawl import FirecrawlApp, ScrapeOptions

app = FirecrawlApp(api_key="fc-YOUR_API_KEY")

search_result = app.search(
    "protected content",
    limit=3,
    scrape_options=ScrapeOptions(
        formats=["markdown"],
        proxy="stealth"  # Options: "basic", "stealth", "auto"
    )
)
```

```js JavaScript
import FirecrawlApp from '@mendable/firecrawl-js';

const app = new FirecrawlApp({apiKey: "fc-YOUR_API_KEY"});

app.search("protected content", {
  limit: 3,
  scrapeOptions: {
    formats: ["markdown"],
    proxy: "stealth"  // Options: "basic", "stealth", "auto"
  }
});
```

```bash cURL
curl -X POST https://api.firecrawl.dev/v1/search \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer fc-YOUR_API_KEY" \
  -d '{
    "query": "protected content",
    "limit": 3,
    "scrapeOptions": {
      "formats": ["markdown"],
      "proxy": "stealth"
    }
  }'
```

</CodeGroup>

Available proxy options:
- `basic`: Standard proxy (default)
- `stealth`: Advanced anti-bot protection (5x cost)
- `auto`: Automatically choose based on website

### Dynamic Content and Timing

Handle JavaScript-heavy sites and dynamic content:

<CodeGroup>

```python Python
from firecrawl import FirecrawlApp, ScrapeOptions

app = FirecrawlApp(api_key="fc-YOUR_API_KEY")

search_result = app.search(
    "dynamic web apps",
    limit=3,
    scrape_options=ScrapeOptions(
        formats=["markdown"],
        waitFor=3000,  # Wait 3 seconds for content to load
        timeout=30000  # 30 second timeout per page
    )
)
```

```js JavaScript
import FirecrawlApp from '@mendable/firecrawl-js';

const app = new FirecrawlApp({apiKey: "fc-YOUR_API_KEY"});

app.search("dynamic web apps", {
  limit: 3,
  scrapeOptions: {
    formats: ["markdown"],
    waitFor: 3000,  // Wait 3 seconds for content to load
    timeout: 30000  // 30 second timeout per page
  }
});
```

```bash cURL
curl -X POST https://api.firecrawl.dev/v1/search \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer fc-YOUR_API_KEY" \
  -d '{
    "query": "dynamic web apps",
    "limit": 3,
    "scrapeOptions": {
      "formats": ["markdown"],
      "waitFor": 3000,
      "timeout": 30000
    }
  }'
```

</CodeGroup>

### Mobile Emulation and Location

Scrape search results as they appear on mobile devices or from specific locations:

<CodeGroup>

```python Python
from firecrawl import FirecrawlApp, ScrapeOptions

app = FirecrawlApp(api_key="fc-YOUR_API_KEY")

search_result = app.search(
    "mobile responsive design",
    limit=3,
    scrape_options=ScrapeOptions(
        formats=["markdown", "screenshot"],
        mobile=True,
        location={
            "country": "JP",
            "languages": ["ja", "en"]
        }
    )
)
```

```js JavaScript
import FirecrawlApp from '@mendable/firecrawl-js';

const app = new FirecrawlApp({apiKey: "fc-YOUR_API_KEY"});

app.search("mobile responsive design", {
  limit: 3,
  scrapeOptions: {
    formats: ["markdown", "screenshot"],
    mobile: true,
    location: {
      country: "JP",
      languages: ["ja", "en"]
    }
  }
});
```

```bash cURL
curl -X POST https://api.firecrawl.dev/v1/search \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer fc-YOUR_API_KEY" \
  -d '{
    "query": "mobile responsive design",
    "limit": 3,
    "scrapeOptions": {
      "formats": ["markdown", "screenshot"],
      "mobile": true,
      "location": {
        "country": "JP",
        "languages": ["ja", "en"]
      }
    }
  }'
```

</CodeGroup>

### Custom Headers and Caching

Add custom headers and control caching behavior:

<CodeGroup>

```python Python
from firecrawl import FirecrawlApp, ScrapeOptions

app = FirecrawlApp(api_key="fc-YOUR_API_KEY")

search_result = app.search(
    "api documentation",
    limit=3,
    scrape_options=ScrapeOptions(
        formats=["markdown"],
        headers={
            "User-Agent": "MyBot/1.0",
            "Accept-Language": "en-US,en;q=0.9"
        },
        maxAge=3600000,  # Cache for 1 hour (in milliseconds)
        blockAds=True
    )
)
```

```js JavaScript
import FirecrawlApp from '@mendable/firecrawl-js';

const app = new FirecrawlApp({apiKey: "fc-YOUR_API_KEY"});

app.search("api documentation", {
  limit: 3,
  scrapeOptions: {
    formats: ["markdown"],
    headers: {
      "User-Agent": "MyBot/1.0",
      "Accept-Language": "en-US,en;q=0.9"
    },
    maxAge: 3600000,  // Cache for 1 hour (in milliseconds)
    blockAds: true
  }
});
```

```bash cURL
curl -X POST https://api.firecrawl.dev/v1/search \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer fc-YOUR_API_KEY" \
  -d '{
    "query": "api documentation",
    "limit": 3,
    "scrapeOptions": {
      "formats": ["markdown"],
      "headers": {
        "User-Agent": "MyBot/1.0",
        "Accept-Language": "en-US,en;q=0.9"
      },
      "maxAge": 3600000,
      "blockAds": true
    }
  }'
```

</CodeGroup>

## Cost Implications

When using the search endpoint with scraping enabled, be aware of these cost factors:

- **Standard scraping**: 1 credit per search result URL
- **PDF parsing**: 1 credit per PDF page (can significantly increase costs for multi-page PDFs)
- **Stealth proxy mode**: +4 additional credits per search result URL (5 total credits per result)
- **Screenshots**: No additional cost beyond the base scraping cost

To control costs:
- Set `parsePDF: false` if you don't need PDF content
- Use `proxy: "basic"` instead of `"stealth"` when possible
- Limit the number of search results with the `limit` parameter

For more details about all available scraping options, refer to the [Scrape Feature documentation](https://docs.firecrawl.dev/features/scrape).
